---
title: "Setting up your project: preparing the scaffolding"
author: "Elise Gould"
date: "30/01/2017"
output: 
  html_document: 
    fig_caption: yes
    keep_md: yes
---

# Create a new Github repository

But first set up a repository on github for version control:

1. Login to github.com and create a new repository
2. In the create new repository screen, give your repository the name: VicBioCon17
3. Give a description of your choosing
4. keep it public
5. Initialize this repository with a README
5. Add a license: select MIT
7. click on create the repository (short: repo)

- Click on the green button "Clone or Download":
- clone with HTTPS: Click the clipboard button to copy the URL.

Your repository is created:

- Note that all files are listed, we have two files at the moment.
- the README page is 'rendered' below

# Create New RStudio Project

File > New Project
Select: Version Control, checkout a project from a version control repository.
Select: Clone a project from a Git repository

In the dialogue box, paste the URL you copied from the github repository.
Hit tab,
Choose where you would like the project to go on your loca computer under 'Create project as subdirectory of:'
Hit create project

Take a look at the "Files" tab. This tab lists all the files and folders in the project directory. You will now see that RStudio has added two files, in addition to downloading the existing files from the github repository. 

- .gitignore file: we will touch on this shortly when we go over version control
- .RProj file: This file contains various project options. You can use this as a shortcut for opening the project directly from your file browser. 

# Setting up your project directory

Putting thought into the scaffolding of your project directory is very important for reducing the risk of mistakes and for minimising head-aches down the track as your project matures. A good project directory scaffolding has a well-defined folder system, clear rules about what type of file goes where, and how those files get there. Importantly, a good project directory layout will facilitate the use of good workflows, ensuring the integrity of your analyses.

There are many ways for you to layout your folders, and the optimal layout will depend on the size and type of project as well as personal preferences. The scaffolding we will use today looks like this:

```
your_project/
├── R/
├── data/
├── doc/
├── figs/
├── output/
├── analysis.R
├── .gitignore
├── README
└── your_project.Rproj
```

## How to use this scaffolding:

`R/` Contains functions or re-usable chunks of code, each defined in their own R script.

`data/` Contains the raw dataset used in your analyses. Usually csv files, but could be in some other format, such as a databse.

`doc/` Contains your paper, thesis, or other main document that your analyses will be used in. Using RMarkdown files is a good idea, so you can load your figures directly from `./fig/`, rather than cpying and pasting. If you like to do exploratory analyses, or investigations before proceeding with the main analysis, you could add two further sub-directories: `./doc/man/` for the main manuscript, and `./doc/inst/` for your investigations. You can move mature sections from the investigations folder to your main manuscript in the `/man/` folder when you are ready.

`figs/` This folder contains your figures. Only generated files go here. I.e. files that are generated by your code written within your analysis script(s).

`output/` Any other non-figure files that are generated by your code should be saved here. These will often be processed versions of your raw dataset (i.e. the cleaned dataset, or specific versions of the dataset shaped for particular analyses), or simulated data.

`analysis.R` Your code driving the entire analysis should be stored here. As your project expands you might find it useful to divide your file up into numbered analysis files. Each file or script should complete one or a few tasks (Gandrud, 2016).

## Principles underpinning this scaffolding:

*1. Keep your data as raw as possible, and read-only*

Original data as read-only, raw vs. processed data.

Lots of effort and money go into collecting data. Therefore it's important that we interact with them in such a way that maintains the integrity of the data. This allows for the data to be re-used by others, perhaps for meta-analyses or for longitudinal studies. Importantly, it will also ensure the integrity of your own analyses and your project, reducing the risk of any irrecoverable, and even unnoticed, errors to your raw data.

One way in which to achieve this is to keep your data 'as raw as possible' by treating the original data file(s) as read-only. This means NOT using Excel to edit your data files directly. It also means that any modifications to your data, either for cleaning, summarising and or analysing, should occur within R, should be well-documented and saved to a script. Modifications should not be saved over the original 'raw' file. Any 'derived' data files should be saved as a separate file. Appending the file names for a given dataset with `_raw` and `_processed`, is a good way of differentiating between these two different versions of the data.

*2. Treat generated output as disposable*

Any files generated by your analysis should go into the `./figs/` or the `./output/` directory. The former containing any figures generated by your code, and the latter containing any type of output files, including simulation outputs, or processed datasets, i.e. those data files ending in `_processed`. By deleting the files, and re-running your analysis scripts, you will be able to regenerate them.

*3. DRY & Define your functions separately from their application*

DRY: Do not Repeat Yourself. Any chunk of code that you re-use more than twice should go into its own script, and turned into a function. These should be saved, a function per file, in the `./R/` folder. The function should be well-documented, including its aim and any other relevent information about usage.

Any time you wish to *apply* a function defined in your `./R/` folder, it should be loaded using `source()`, and saved into your analysis script, in the example scaffolding above, `analysis.R`.

### Challenge 1 (5-minute)

1. Set up your project skeleton by adding new folders according to the project directory template outlined above. Hint: Click on 'New Folder' to add folders.

2. Download the datasets for today's workshop from here: [https://github.com/egouldo/VicBioCon17_data_wrangling](https://github.com/egouldo/VicBioCon17_data_wrangling). They are called `bat_dat.csv` and `iris.csv` and are in the `./data/` directory. You can download them by: clicking on the filename for the relevant document within the folder view, when viewing each individual file within GitHub, right-click on the "raw" button, and select "save target as", "download file as", etc (specific option will depend on your computer's operating system). ![download_data](../assets/download_data.png)

3. Save it to the appropriate folder in your project.

### References:

[nice R code guide](https://nicercode.github.io/blog/2013-04-05-projects/)

[Another way of organising the project directory: http://www.carlboettiger.info/2012/05/06/research-workflow.html](http://www.carlboettiger.info/2012/05/06/research-workflow.html)

Gandrud, C. (2016) Reproducible Research with R and R Studio, Second Edition. CRC Press.

White, E., Baldridge, E., Brym, Z., Locey, K., McGlinn, D., Supp, S. (2013) Nine simple ways to make it easier to (re)use your data. IEE. 6, 1–10.

Noble, W. S. (2009) A Quick Guide to Organizing Computational Biology Projects (ed F. Lewitter). PLoS Comp Biol. 5, e1000424.





